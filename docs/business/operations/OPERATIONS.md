# OpÃ©rations - VMCloud

> **Source de vÃ©ritÃ©** pour les processus opÃ©rationnels et l'excellence ops
> DerniÃ¨re mise Ã  jour : DÃ©cembre 2024
> Statut : Early-stage (Ã©quipe rÃ©duite, process en construction)

---

## Executive Summary

VMCloud opÃ¨re en mode **lean ops** avec une Ã©quipe technique rÃ©duite gÃ©rant l'infrastructure et le support. L'objectif est de maximiser l'automatisation pour permettre le scale sans augmentation proportionnelle de l'Ã©quipe.

```
MÃ‰TRIQUES OPS VMCLOUD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

INFRASTRUCTURE
â”œâ”€â”€ Clients actifs : ~10
â”œâ”€â”€ VMs en production : ~80
â”œâ”€â”€ GPU instances : ~20
â””â”€â”€ Uptime (2024) : 99.9%

INCIDENTS
â”œâ”€â”€ P0 (critiques) / an : 0
â”œâ”€â”€ P1 (majeurs) / an : 2
â”œâ”€â”€ P2 (modÃ©rÃ©s) / mois : 1-2
â”œâ”€â”€ MTTR moyen : < 30 min
â””â”€â”€ MTTD : < 2 min (automated)

Ã‰QUIPE OPS
â”œâ”€â”€ SRE : 1 contractor (15.4Kâ‚¬/mois)
â”œâ”€â”€ Support : Fondateur + CRE
â”œâ”€â”€ On-call : 24/7 via astreinte
â””â”€â”€ Ratio clients/ops : 10:1 (cible 100:1)
```

---

## 1. Vue d'ensemble des OpÃ©rations

### 1.1 PÃ©rimÃ¨tre opÃ©rationnel

```
SCOPE OPERATIONS VMCLOUD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SERVICES MANAGÃ‰S
â”œâ”€â”€ VPS (Compute) : 8 tiers
â”œâ”€â”€ GPU Cloud : 4 types GPUs
â”œâ”€â”€ Web Hosting : 3 tiers
â”œâ”€â”€ PaaS : Containers, apps
â”œâ”€â”€ Load Balancer : HAProxy
â”œâ”€â”€ Block Storage : Ceph
â”œâ”€â”€ Object Storage : S3-compatible
â””â”€â”€ CDN : BunnyCDN integration

PÃ‰RIMÃˆTRE RESPONSABILITÃ‰
â”œâ”€â”€ Infrastructure physique : OVH (provider)
â”œâ”€â”€ Virtualisation : VMCloud
â”œâ”€â”€ Network L3+ : VMCloud
â”œâ”€â”€ Storage : VMCloud
â”œâ”€â”€ Backup : VMCloud
â”œâ”€â”€ Monitoring : VMCloud
â”œâ”€â”€ Support : VMCloud
â””â”€â”€ Billing : VMCloud

HORS PÃ‰RIMÃˆTRE
â”œâ”€â”€ Hardware (via OVH)
â”œâ”€â”€ DC facilities (via OVH)
â”œâ”€â”€ Contenu client (responsabilitÃ© client)
â””â”€â”€ Applications client (responsabilitÃ© client)
```

### 1.2 Organisation ops actuelle

```
STRUCTURE Ã‰QUIPE OPS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE ACTUELLE (Early-stage)

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    FONDATEUR    â”‚
         â”‚   (CEO/CTO)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚  SRE  â”‚   â”‚    CRE    â”‚   â”‚ DEVS  â”‚
â”‚       â”‚   â”‚(Customer  â”‚   â”‚(Part- â”‚
â”‚15.4Kâ‚¬ â”‚   â”‚ Rel Eng)  â”‚   â”‚ time) â”‚
â”‚/mois  â”‚   â”‚  4Kâ‚¬/mois â”‚   â”‚       â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      RESPONSABILITÃ‰S          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SRE:                          â”‚
â”‚ - Infrastructure              â”‚
â”‚ - Monitoring                  â”‚
â”‚ - Incidents P0/P1             â”‚
â”‚ - Automatisation              â”‚
â”‚                               â”‚
â”‚ CRE:                          â”‚
â”‚ - Support client L1/L2        â”‚
â”‚ - Onboarding                  â”‚
â”‚ - Tickets non-techniques      â”‚
â”‚                               â”‚
â”‚ Fondateur:                    â”‚
â”‚ - Escalation P0               â”‚
â”‚ - DÃ©cisions architecture      â”‚
â”‚ - Support Enterprise          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰QUIPE CIBLE (MRR > 50Kâ‚¬)
â”œâ”€â”€ SRE Lead : 1
â”œâ”€â”€ SRE Junior : 1
â”œâ”€â”€ Support Lead : 1
â”œâ”€â”€ Support Agent : 1
â””â”€â”€ DevOps : 1
```

---

## 2. Monitoring et Alerting

### 2.1 Stack de monitoring

```
STACK MONITORING VMCLOUD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MÃ‰TRIQUES INFRASTRUCTURE
â”œâ”€â”€ Collecte : Prometheus
â”œâ”€â”€ Storage : Victoria Metrics (long-term)
â”œâ”€â”€ Visualisation : Grafana
â”œâ”€â”€ Coverage : 100% des hosts
â””â”€â”€ RÃ©tention : 90 jours detail, 1 an aggregated

LOGS
â”œâ”€â”€ Collecte : Fluentd / Vector
â”œâ”€â”€ Storage : Loki (Grafana stack)
â”œâ”€â”€ Search : LogQL
â”œâ”€â”€ Coverage : 100% des services
â””â”€â”€ RÃ©tention : 30 jours

UPTIME / SYNTHETICS
â”œâ”€â”€ Tool : UptimeRobot + internal
â”œâ”€â”€ Endpoints : 50+ monitored
â”œâ”€â”€ FrÃ©quence : 1 minute
â”œâ”€â”€ Alertes : Slack + PagerDuty
â””â”€â”€ Status page : status.vmcloud.com

APM / TRACES (LimitÃ©)
â”œâ”€â”€ Tool : Jaeger (internal APIs only)
â”œâ”€â”€ Coverage : ~30%
â”œâ”€â”€ Usage : Debug, non systematique
â””â”€â”€ Roadmap : Expand in 2025

CLIENT METRICS
â”œâ”€â”€ Dashboard client : Basic (CPU, RAM, disk)
â”œâ”€â”€ Alertes client : Non (roadmap)
â”œâ”€â”€ MÃ©triques custom : Non
â””â”€â”€ Roadmap : Client alerting Q2 2025
```

### 2.2 Dashboards

```
DASHBOARDS OPÃ‰RATIONNELS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DASHBOARD PRINCIPAL (NOC)
â”œâ”€â”€ Vue globale : SantÃ© de tous les services
â”œâ”€â”€ Alertes actives : Liste temps rÃ©el
â”œâ”€â”€ CapacitÃ© : CPU, RAM, Storage, Network
â””â”€â”€ Clients impactÃ©s : Si incident

DASHBOARDS PAR SERVICE
â”œâ”€â”€ Compute : VMs par DC, utilisation, migrations
â”œâ”€â”€ Storage : CapacitÃ© Ceph, latency, IOPS
â”œâ”€â”€ Network : Bandwidth, packets, errors
â”œâ”€â”€ GPU : Allocation, tempÃ©rature, utilisation
â””â”€â”€ API : Requests, latency, errors

DASHBOARDS BUSINESS
â”œâ”€â”€ Clients actifs : Nombre, growth
â”œâ”€â”€ VMs : Total, crÃ©Ã©es/supprimÃ©es
â”œâ”€â”€ Revenue : MRR, usage
â””â”€â”€ Support : Tickets, SLA

DASHBOARDS CLIENT (Self-service)
â”œâ”€â”€ VM metrics : CPU, RAM, Disk, Network
â”œâ”€â”€ Status : Up/Down
â”œâ”€â”€ Console : SSH, VNC
â””â”€â”€ Logs : LimitÃ© (roadmap)

ACCÃˆS
â”œâ”€â”€ Team : Grafana interne
â”œâ”€â”€ Clients : Console VMCloud
â”œâ”€â”€ Public : status.vmcloud.com
â””â”€â”€ Alertes : Slack #alerts, PagerDuty
```

### 2.3 Alerting

```
NIVEAUX D'ALERTE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

P0 - CRITIQUE (Service down)
â”œâ”€â”€ DÃ©finition : Service client totalement indisponible
â”œâ”€â”€ Exemples : DC down, API down, Storage down
â”œâ”€â”€ Response time : < 5 minutes
â”œâ”€â”€ Notification : PagerDuty + Phone + Slack
â”œâ”€â”€ Escalation : ImmÃ©diate Ã  SRE + Fondateur
â””â”€â”€ Target MTTR : < 30 minutes

P1 - HIGH (DÃ©gradation majeure)
â”œâ”€â”€ DÃ©finition : FonctionnalitÃ© majeure impactÃ©e
â”œâ”€â”€ Exemples : Network degraded, VM provisionning slow
â”œâ”€â”€ Response time : < 15 minutes
â”œâ”€â”€ Notification : PagerDuty + Slack
â”œâ”€â”€ Escalation : SRE, puis Fondateur si > 1h
â””â”€â”€ Target MTTR : < 2 heures

P2 - MEDIUM (Impact limitÃ©)
â”œâ”€â”€ DÃ©finition : FonctionnalitÃ© mineure impactÃ©e
â”œâ”€â”€ Exemples : Monitoring gap, Console slow
â”œâ”€â”€ Response time : < 1 heure
â”œâ”€â”€ Notification : Slack only
â”œâ”€â”€ Escalation : Heures ouvrÃ©es
â””â”€â”€ Target MTTR : < 24 heures

P3 - LOW (CosmÃ©tique)
â”œâ”€â”€ DÃ©finition : Pas d'impact utilisateur
â”œâ”€â”€ Exemples : Log errors, deprecation warnings
â”œâ”€â”€ Response time : Next business day
â”œâ”€â”€ Notification : Email / ticket
â”œâ”€â”€ Escalation : Weekly review
â””â”€â”€ Target MTTR : 1 semaine

ROUTING ALERTES
â”œâ”€â”€ P0/P1 : PagerDuty â†’ SRE on-call â†’ Phone
â”œâ”€â”€ P2 : Slack #alerts â†’ Review heures ouvrÃ©es
â”œâ”€â”€ P3 : Email / Jira â†’ Backlog
â””â”€â”€ Business hours : Slack notification to all
```

---

## 3. Gestion des Incidents

### 3.1 Process incident

```
INCIDENT MANAGEMENT PROCESS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. DÃ‰TECTION (< 2 min)
â”œâ”€â”€ Source : Automated (90%) / Client report (10%)
â”œâ”€â”€ Alerting : Prometheus â†’ AlertManager â†’ PagerDuty
â”œâ”€â”€ Auto-ack : Si pas d'ack dans 5 min, escalate
â””â”€â”€ Notification : Slack #incidents

2. TRIAGE (< 5 min)
â”œâ”€â”€ Responsable : On-call SRE
â”œâ”€â”€ Actions :
â”‚   â”œâ”€â”€ Identifier le service impactÃ©
â”‚   â”œâ”€â”€ Ã‰valuer la sÃ©vÃ©ritÃ© (P0-P3)
â”‚   â”œâ”€â”€ Identifier les clients impactÃ©s
â”‚   â””â”€â”€ DÃ©cider : Fix vs Escalate vs Monitor
â””â”€â”€ Communication : Update Slack, status page si P0/P1

3. INVESTIGATION (Time-boxed)
â”œâ”€â”€ P0 : Max 15 min avant escalation
â”œâ”€â”€ P1 : Max 30 min avant escalation
â”œâ”€â”€ Tools : Grafana, Logs, SSH access
â””â”€â”€ Documentation : Notes en temps rÃ©el

4. RESOLUTION
â”œâ”€â”€ Fix identifiÃ© : Apply + Verify
â”œâ”€â”€ Rollback si applicable
â”œâ”€â”€ Workaround si fix long
â””â”€â”€ Confirm with monitoring

5. POST-INCIDENT
â”œâ”€â”€ Notification : Clients + Status page
â”œâ”€â”€ Post-mortem : Obligatoire si P0/P1
â”œâ”€â”€ Timeline : Post-mortem dans 48h
â””â”€â”€ Actions : Assign preventive tasks

6. CLOSURE
â”œâ”€â”€ Incident closed dans le tracker
â”œâ”€â”€ Client communication if needed
â”œâ”€â”€ Metrics updated
â””â”€â”€ Lessons learned shared
```

### 3.2 Astreintes (On-call)

```
ORGANISATION ON-CALL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

COVERAGE
â”œâ”€â”€ Heures : 24/7/365
â”œâ”€â”€ Rotation : Hebdomadaire
â”œâ”€â”€ Ã‰quipe : SRE + Fondateur (backup)
â””â”€â”€ Vacances : Swap anticipÃ©

SCHEDULE
â”œâ”€â”€ Primary : SRE contractor
â”œâ”€â”€ Secondary : Fondateur (CTO)
â”œâ”€â”€ Escalation : CEO si besoin
â””â”€â”€ Response SLA : < 15 min

COMPENSATION
â”œâ”€â”€ Astreinte base : Inclus dans contrat SRE
â”œâ”€â”€ Intervention nuit/WE : 1.5Ã— si > 1h
â”œâ”€â”€ P0 incidents : Bonus si rÃ©solu < MTTR
â””â”€â”€ Budget on-call : ~500â‚¬/mois extra

OUTILS
â”œâ”€â”€ Alerting : PagerDuty
â”œâ”€â”€ Communication : Slack + Phone
â”œâ”€â”€ Access : VPN + Bastion (depuis n'importe oÃ¹)
â”œâ”€â”€ Runbooks : Notion / GitHub
â””â”€â”€ War room : Google Meet (si besoin)

ESCALATION PATH
â”œâ”€â”€ T+0 : Alerte PagerDuty
â”œâ”€â”€ T+5 min : Phone call si pas d'ack
â”œâ”€â”€ T+15 min : Escalate au secondary
â”œâ”€â”€ T+30 min : Escalate au CEO
â””â”€â”€ T+60 min : All hands
```

### 3.3 MÃ©triques incidents

```
KPIS INCIDENT MANAGEMENT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VOLUME
â”œâ”€â”€ Incidents P0-P1 / an : Cible < 5
â”œâ”€â”€ Incidents P2 / mois : Cible < 3
â”œâ”€â”€ False positives / mois : Cible < 10
â””â”€â”€ Client-reported : Cible < 20%

TEMPS
â”œâ”€â”€ MTTD (Time to Detect) : Cible < 2 min
â”œâ”€â”€ MTTA (Time to Acknowledge) : Cible < 5 min
â”œâ”€â”€ MTTR P0 : Cible < 30 min
â”œâ”€â”€ MTTR P1 : Cible < 2h
â”œâ”€â”€ MTTR P2 : Cible < 24h
â””â”€â”€ Post-mortem completion : < 48h

QUALITÃ‰
â”œâ”€â”€ SLA breaches / an : Cible 0
â”œâ”€â”€ Repeat incidents : Cible < 10%
â”œâ”€â”€ Root cause identified : > 95%
â””â”€â”€ Preventive actions completed : > 80%

ACTUEL (2024)
â”œâ”€â”€ P0 incidents : 0
â”œâ”€â”€ P1 incidents : 2
â”œâ”€â”€ MTTR moyen : ~25 min
â”œâ”€â”€ Client-reported : ~15%
â””â”€â”€ SLA breaches : 0
```

---

## 4. Change Management

### 4.1 Process de dÃ©ploiement

```
DEPLOYMENT PROCESS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ENVIRONNEMENTS
â”œâ”€â”€ Dev : Local / feature branches
â”œâ”€â”€ Staging : staging.vmcloud.com (isolated)
â”œâ”€â”€ Production : vmcloud.com
â””â”€â”€ Canary : 5% traffic (pour changes majeurs)

FRÃ‰QUENCE DE DEPLOY
â”œâ”€â”€ API/Backend : 2-5Ã— / semaine
â”œâ”€â”€ Frontend : 2-3Ã— / semaine
â”œâ”€â”€ Infrastructure : Hebdomadaire (maintenance window)
â””â”€â”€ Database : Ad-hoc (avec review)

CI/CD PIPELINE
â”œâ”€â”€ Source : GitHub
â”œâ”€â”€ CI : GitHub Actions
â”œâ”€â”€ Tests : Unit + Integration (80% coverage)
â”œâ”€â”€ Build : Docker images
â”œâ”€â”€ Registry : Harbor (private)
â”œâ”€â”€ Deploy : Kubernetes (K3s)
â””â”€â”€ Monitoring : Auto-rollback si errors spike

VALIDATION REQUISE
â”œâ”€â”€ Code review : 1 approval minimum
â”œâ”€â”€ Tests : All green
â”œâ”€â”€ Staging : 1h minimum
â”œâ”€â”€ Security scan : Trivy (containers)
â””â”€â”€ Manual QA : Pour features majeures
```

### 4.2 Types de changements

```
CLASSIFICATION DES CHANGES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

STANDARD (Low risk)
â”œâ”€â”€ DÃ©finition : Changes prÃ©-approuvÃ©s, routine
â”œâ”€â”€ Exemples : Dependency updates, minor fixes
â”œâ”€â”€ Approval : Auto (via CI/CD)
â”œâ”€â”€ Lead time : < 1 jour
â”œâ”€â”€ Rollback : Automatique
â””â”€â”€ Window : Anytime

NORMAL (Medium risk)
â”œâ”€â”€ DÃ©finition : Features, modifications significatives
â”œâ”€â”€ Exemples : New feature, API change, config change
â”œâ”€â”€ Approval : Code review + QA
â”œâ”€â”€ Lead time : 1-3 jours
â”œâ”€â”€ Rollback : < 5 min (container rollback)
â””â”€â”€ Window : Business hours prÃ©fÃ©rÃ©

EMERGENCY (Hotfix)
â”œâ”€â”€ DÃ©finition : Fix critique, security patch
â”œâ”€â”€ Exemples : Bug bloquant, vulnÃ©rabilitÃ©
â”œâ”€â”€ Approval : 1 approver + post-review
â”œâ”€â”€ Lead time : < 4 heures
â”œâ”€â”€ Rollback : PrÃ©parÃ© avant deploy
â””â”€â”€ Window : ImmÃ©diat

MAJOR (High risk)
â”œâ”€â”€ DÃ©finition : Infrastructure, DB migrations
â”œâ”€â”€ Exemples : DC migration, schema change, major upgrade
â”œâ”€â”€ Approval : CTO + review complet
â”œâ”€â”€ Lead time : 1-2 semaines
â”œâ”€â”€ Rollback : Plan documentÃ©, testÃ©
â””â”€â”€ Window : Maintenance window (dimanche 3h-6h)
```

### 4.3 Maintenance windows

```
MAINTENANCE PLANIFIÃ‰E
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCHEDULE
â”œâ”€â”€ Window rÃ©guliÃ¨re : Dimanche 03:00-06:00 CET
â”œâ”€â”€ FrÃ©quence : Hebdomadaire (si nÃ©cessaire)
â”œâ”€â”€ DurÃ©e max : 3 heures
â””â”€â”€ Client notification : 72h minimum (email + status page)

TYPES DE MAINTENANCE
â”œâ”€â”€ Security patches : Mensuel
â”œâ”€â”€ OS updates : Trimestriel
â”œâ”€â”€ Hardware maintenance : Via OVH (rare)
â”œâ”€â”€ Database maintenance : Mensuel
â””â”€â”€ Major upgrades : Trimestriel

PROCESS
â”œâ”€â”€ J-7 : Planification et communication
â”œâ”€â”€ J-3 : Reminder clients
â”œâ”€â”€ J-1 : PrÃ©paration, tests en staging
â”œâ”€â”€ J : ExÃ©cution + monitoring
â”œâ”€â”€ J+1 : VÃ©rification, post-maintenance report
â””â”€â”€ Post : Update changelog

IMPACT MINIMISÃ‰
â”œâ”€â”€ Rolling updates : Oui (zero downtime)
â”œâ”€â”€ Live migration VMs : Oui
â”œâ”€â”€ Storage maintenance : Online (Ceph)
â”œâ”€â”€ Network changes : < 30s interruption
â””â”€â”€ Full DC maintenance : TrÃ¨s rare, avec migration
```

---

## 5. Capacity Planning

### 5.1 CapacitÃ© actuelle

```
UTILISATION DES RESSOURCES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

COMPUTE
â”œâ”€â”€ vCPUs total : 6,000 (allocable)
â”œâ”€â”€ vCPUs utilisÃ©s : ~800 (13%)
â”œâ”€â”€ RAM total : 14 TB (allocable)
â”œâ”€â”€ RAM utilisÃ©e : ~2 TB (14%)
â””â”€â”€ Headroom : 80%+ disponible

GPU
â”œâ”€â”€ Total : 85 units
â”œâ”€â”€ UtilisÃ©s : ~35 (40%)
â”œâ”€â”€ T4 : 10/25 (40%)
â”œâ”€â”€ 4090 : 15/20 (75%) - Hackboot
â”œâ”€â”€ A100 40GB : 8/30 (27%)
â”œâ”€â”€ A100 80GB : 2/10 (20%)
â””â”€â”€ Headroom : 60% disponible

STORAGE
â”œâ”€â”€ Total : 100 TB brut (~33 TB usable)
â”œâ”€â”€ UtilisÃ© : ~8 TB (24%)
â””â”€â”€ Headroom : 75%+ disponible

NETWORK
â”œâ”€â”€ Bandwidth : 100 Gbps
â”œâ”€â”€ Peak usage : ~10 Gbps
â””â”€â”€ Headroom : 90%
```

### 5.2 Projections et seuils

```
CAPACITY PLANNING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SEUILS D'ALERTE
â”œâ”€â”€ CPU > 60% : Yellow (plan expansion)
â”œâ”€â”€ CPU > 80% : Red (urgent expansion)
â”œâ”€â”€ RAM > 70% : Yellow
â”œâ”€â”€ RAM > 85% : Red
â”œâ”€â”€ Storage > 70% : Yellow
â”œâ”€â”€ Storage > 85% : Red
â”œâ”€â”€ GPU > 70% : Yellow (popular models)
â””â”€â”€ GPU > 90% : Red

LEAD TIME EXPANSION
â”œâ”€â”€ Compute (via OVH) : 2-4 semaines
â”œâ”€â”€ GPU (via OVH) : 4-8 semaines
â”œâ”€â”€ Storage : 1-2 semaines
â””â”€â”€ Network : 1 semaine

PROJECTIONS (2025)
â”œâ”€â”€ Clients : 10 â†’ 200
â”œâ”€â”€ vCPU usage : 800 â†’ 4,000 (66%)
â”œâ”€â”€ GPU usage : 35 â†’ 70 (82%)
â”œâ”€â”€ Storage : 8 TB â†’ 30 TB (90%)
â””â”€â”€ Action : Commander GPU Q2 si croissance

BUDGET CAPACITY
â”œâ”€â”€ Dans programme OVH : Via crÃ©dits
â”œâ”€â”€ Extra compute : ~600â‚¬/serveur/mois
â”œâ”€â”€ Extra GPU : 300-4000â‚¬/GPU/mois
â””â”€â”€ Reserve : Demander avant 70% usage
```

### 5.3 Process capacity review

```
CAPACITY REVIEW PROCESS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

WEEKLY
â”œâ”€â”€ Check utilisation dashboards
â”œâ”€â”€ Identify trends
â”œâ”€â”€ Flag si > 60% sur ressource

MONTHLY
â”œâ”€â”€ Capacity report
â”œâ”€â”€ Forecast next 3 months
â”œâ”€â”€ Order si needed (lead time)

QUARTERLY
â”œâ”€â”€ Review annuelle extrapolation
â”œâ”€â”€ Budget planning
â”œâ”€â”€ Infrastructure roadmap update

TRIGGERS D'ACTION
â”œâ”€â”€ > 60% utilisation : Planning
â”œâ”€â”€ > 70% utilisation : Order process
â”œâ”€â”€ > 80% utilisation : Emergency order
â”œâ”€â”€ Customer request large : Pre-provision
â””â”€â”€ New DC : 6+ months planning
```

---

## 6. Backup et Disaster Recovery

### 6.1 StratÃ©gie de backup

```
BACKUP STRATEGY VMCLOUD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VMS CLIENTS (Block storage)
â”œâ”€â”€ FrÃ©quence : Daily (automated)
â”œâ”€â”€ Type : Incremental snapshots
â”œâ”€â”€ RÃ©tention : 7 jours default
â”œâ”€â”€ Extended : 30 jours (option payante)
â”œâ”€â”€ Localisation : Same DC
â”œâ”€â”€ Off-site : Weekly to different DC
â””â”€â”€ Restore : Self-service via console

DATABASES (Platform)
â”œâ”€â”€ FrÃ©quence : Every 6 hours
â”œâ”€â”€ Type : Full + WAL shipping (Postgres)
â”œâ”€â”€ RÃ©tention : 30 jours
â”œâ”€â”€ Localisation : Cross-DC
â”œâ”€â”€ Point-in-time recovery : Oui
â””â”€â”€ Test restore : Mensuel

CONFIGURATION
â”œâ”€â”€ Infrastructure as Code : Git (GitHub)
â”œâ”€â”€ Secrets : HashiCorp Vault
â”œâ”€â”€ Config : Ansible playbooks
â”œâ”€â”€ State : Terraform state (encrypted)
â””â”€â”€ Backup : Git + off-site

LOGS
â”œâ”€â”€ RÃ©tention : 30 jours (Loki)
â”œâ”€â”€ Archive : 90 jours (S3 glacier)
â””â”€â”€ Critical logs : 1 an

BILLING / BUSINESS DATA
â”œâ”€â”€ Database : Postgres backup
â”œâ”€â”€ Invoices : PDF stored S3
â”œâ”€â”€ RÃ©tention : 10 ans (legal)
â””â”€â”€ Localisation : Multi-DC
```

### 6.2 Tests de restauration

```
RESTORE TESTING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

VM RESTORE
â”œâ”€â”€ FrÃ©quence : Mensuel
â”œâ”€â”€ Process : Restore random VM to test env
â”œâ”€â”€ Validation : Boot, data integrity
â”œâ”€â”€ Dernier test : [Ã€ documenter]
â”œâ”€â”€ RTO testÃ© : < 30 min
â””â”€â”€ RPO testÃ© : 24h (daily backup)

DATABASE RESTORE
â”œâ”€â”€ FrÃ©quence : Mensuel
â”œâ”€â”€ Process : Restore to staging
â”œâ”€â”€ Validation : Query tests, data check
â”œâ”€â”€ Dernier test : [Ã€ documenter]
â”œâ”€â”€ RTO testÃ© : < 1h
â””â”€â”€ RPO testÃ© : < 6h (WAL)

FULL DR TEST
â”œâ”€â”€ FrÃ©quence : Annuel
â”œâ”€â”€ Process : Simuler perte d'un DC
â”œâ”€â”€ Scope : Recovery dans DC secondaire
â”œâ”€â”€ Dernier test : [Ã€ planifier]
â”œâ”€â”€ RTO cible : 4-8h
â””â”€â”€ RPO cible : 24h
```

### 6.3 Disaster Recovery

```
DR SCENARIOS ET RÃ‰PONSES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 1 : PANNE SERVEUR
â”œâ”€â”€ Impact : VMs sur ce host down
â”œâ”€â”€ DÃ©tection : < 1 min (health check)
â”œâ”€â”€ Recovery : Auto-restart sur autre host
â”œâ”€â”€ RTO : < 5 min
â”œâ”€â”€ RPO : 0 (storage intact)
â””â”€â”€ Action : Automatique

SCENARIO 2 : PANNE RACK
â”œâ”€â”€ Impact : ~10 serveurs down
â”œâ”€â”€ DÃ©tection : < 1 min
â”œâ”€â”€ Recovery : Migration VMs vers autres racks
â”œâ”€â”€ RTO : < 30 min
â”œâ”€â”€ RPO : 0 (storage distributed)
â””â”€â”€ Action : Automatique + vÃ©rification

SCENARIO 3 : PANNE STORAGE
â”œâ”€â”€ Impact : DonnÃ©es inaccessibles
â”œâ”€â”€ DÃ©tection : < 1 min
â”œâ”€â”€ Recovery : Ceph self-healing (si partiel)
â”œâ”€â”€ RTO : Variable (minutes Ã  heures)
â”œâ”€â”€ RPO : 0 (3Ã— replication)
â””â”€â”€ Action : Monitor + intervenir si nÃ©cessaire

SCENARIO 4 : PANNE DC ENTIER
â”œâ”€â”€ Impact : Tous les clients du DC
â”œâ”€â”€ DÃ©tection : < 1 min
â”œâ”€â”€ Recovery :
â”‚   â”œâ”€â”€ Communication immÃ©diate
â”‚   â”œâ”€â”€ Failover vers DC secondaire (manuel)
â”‚   â”œâ”€â”€ Restore depuis backup off-site
â”‚   â””â”€â”€ Client notification pour reconfiguration
â”œâ”€â”€ RTO : 4-24h (manual process)
â”œâ”€â”€ RPO : 24h (daily off-site backup)
â””â”€â”€ Action : Manuel, CEO involved

SCENARIO 5 : CYBERATTAQUE
â”œâ”€â”€ Impact : Variable
â”œâ”€â”€ DÃ©tection : Monitoring sÃ©curitÃ©
â”œâ”€â”€ Recovery :
â”‚   â”œâ”€â”€ Isoler les systÃ¨mes affectÃ©s
â”‚   â”œâ”€â”€ Forensics
â”‚   â”œâ”€â”€ Restore from clean backups
â”‚   â””â”€â”€ Security audit
â”œâ”€â”€ RTO : 24-72h
â”œâ”€â”€ RPO : Dernier backup clean
â””â”€â”€ Action : Incident response plan
```

---

## 7. Automatisation

### 7.1 Infrastructure as Code

```
IaC STACK VMCLOUD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PROVISIONING
â”œâ”€â”€ Tool : Terraform
â”œâ”€â”€ Provider : OVH, Cloudflare
â”œâ”€â”€ State : Terraform Cloud (encrypted)
â”œâ”€â”€ Modules : RÃ©utilisables par service
â””â”€â”€ Coverage : 90% de l'infra

CONFIGURATION
â”œâ”€â”€ Tool : Ansible
â”œâ”€â”€ Inventory : Dynamic (from Terraform)
â”œâ”€â”€ Playbooks : Par role (web, db, monitoring)
â”œâ”€â”€ Secrets : Ansible Vault + HashiCorp Vault
â””â”€â”€ Coverage : 100% des hosts

CONTAINERS
â”œâ”€â”€ Orchestration : Kubernetes (K3s)
â”œâ”€â”€ Manifests : Helm charts
â”œâ”€â”€ GitOps : ArgoCD
â”œâ”€â”€ Images : Harbor registry
â””â”€â”€ Coverage : 100% des apps

DOCUMENTATION
â”œâ”€â”€ All IaC in Git
â”œâ”€â”€ PRs required for changes
â”œâ”€â”€ Automated documentation
â””â”€â”€ Drift detection : Terraform plan scheduled
```

### 7.2 CI/CD Pipeline

```
CI/CD ARCHITECTURE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SOURCE â†’ BUILD â†’ TEST â†’ DEPLOY
   â”‚        â”‚       â”‚       â”‚
GitHub â†’ Actions â†’ Tests â†’ K8s
   â”‚        â”‚       â”‚       â”‚
   â”‚    Docker    Unit    ArgoCD
   â”‚    Build     Integration
   â”‚              E2E
   â”‚
   â””â”€â”€ Feature branch workflow

PIPELINE STAGES
â”œâ”€â”€ 1. Lint & Format : < 1 min
â”œâ”€â”€ 2. Build : < 3 min
â”œâ”€â”€ 3. Unit tests : < 5 min
â”œâ”€â”€ 4. Integration tests : < 10 min
â”œâ”€â”€ 5. Security scan : < 3 min
â”œâ”€â”€ 6. Build Docker image : < 5 min
â”œâ”€â”€ 7. Push to registry : < 1 min
â”œâ”€â”€ 8. Deploy to staging : < 2 min
â”œâ”€â”€ 9. E2E tests : < 10 min
â”œâ”€â”€ 10. Manual approval (if needed)
â”œâ”€â”€ 11. Deploy to production : < 2 min
â””â”€â”€ Total : ~30-45 min

ROLLBACK
â”œâ”€â”€ Type : Kubernetes rollback
â”œâ”€â”€ Trigger : Manual ou auto (error rate)
â”œâ”€â”€ Time : < 1 min
â””â”€â”€ Verification : Health checks
```

### 7.3 Self-healing et automation

```
AUTOMATION CAPABILITIES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SELF-HEALING
â”œâ”€â”€ VM auto-restart : Si host fail
â”œâ”€â”€ Container restart : Kubernetes liveness
â”œâ”€â”€ Service restart : Systemd watchdog
â”œâ”€â”€ Storage : Ceph auto-repair
â””â”€â”€ Network : BGP failover

AUTO-SCALING (Roadmap)
â”œâ”€â”€ VM scaling : Non (manual)
â”œâ”€â”€ Container scaling : Kubernetes HPA
â”œâ”€â”€ Storage scaling : Non (manual)
â””â”€â”€ Roadmap : VM auto-scale Q3 2025

AUTO-REMEDIATION
â”œâ”€â”€ Disk full : Cleanup old logs
â”œâ”€â”€ High memory : Restart service
â”œâ”€â”€ Certificate expiry : Auto-renew
â”œâ”€â”€ Failed deployment : Auto-rollback
â””â”€â”€ DDoS : OVH auto-mitigation

SCHEDULED TASKS
â”œâ”€â”€ Backups : Daily 02:00 UTC
â”œâ”€â”€ Cleanup : Daily 04:00 UTC
â”œâ”€â”€ Certificate renewal : Weekly check
â”œâ”€â”€ Security updates : Weekly scan
â”œâ”€â”€ Capacity report : Daily
â””â”€â”€ Health report : Hourly
```

---

## 8. Documentation OpÃ©rationnelle

### 8.1 Runbooks

```
RUNBOOKS VMCLOUD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

STRUCTURE
â”œâ”€â”€ Title : Description claire
â”œâ”€â”€ Trigger : Quand utiliser
â”œâ”€â”€ Prerequisites : AccÃ¨s requis
â”œâ”€â”€ Steps : Ã‰tapes numÃ©rotÃ©es
â”œâ”€â”€ Verification : Comment vÃ©rifier succÃ¨s
â”œâ”€â”€ Rollback : En cas de problÃ¨me
â””â”€â”€ Contact : Qui escalader

RUNBOOKS EXISTANTS
â”œâ”€â”€ VM Provisioning : CrÃ©er une VM manuellement
â”œâ”€â”€ VM Migration : Migrer VM entre hosts
â”œâ”€â”€ Storage Expansion : Ajouter capacitÃ© Ceph
â”œâ”€â”€ Network Debug : Troubleshoot network issues
â”œâ”€â”€ Database Restore : Restaurer Postgres
â”œâ”€â”€ Certificate Renewal : Manual renewal
â”œâ”€â”€ DDoS Response : GÃ©rer une attaque
â”œâ”€â”€ Customer Onboarding : Setup nouveau client
â””â”€â”€ Incident Response : Process incidents

LOCALISATION
â”œâ”€â”€ Source : GitHub repo /runbooks
â”œâ”€â”€ Format : Markdown
â”œâ”€â”€ AccÃ¨s : Ã‰quipe technique
â””â”€â”€ Backup : Notion (copie)

MAINTENANCE
â”œâ”€â”€ Review : Trimestriel
â”œâ”€â”€ Update : Ã€ chaque changement
â”œâ”€â”€ Owner : SRE
â””â”€â”€ Testing : Post-incident validation
```

### 8.2 Documentation technique

```
DOCUMENTATION TECHNIQUE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ARCHITECTURE
â”œâ”€â”€ Document : ARCHITECTURE.md
â”œâ”€â”€ Statut : âœ… Ã€ jour
â”œâ”€â”€ Contenu : Diagrammes, dÃ©cisions, stack
â””â”€â”€ Localisation : GitHub /docs

NETWORK
â”œâ”€â”€ Document : NETWORK.md
â”œâ”€â”€ Statut : âœ… Ã€ jour
â”œâ”€â”€ Contenu : Diagramme rÃ©seau, IPs, VLANs
â””â”€â”€ Localisation : GitHub /docs

API
â”œâ”€â”€ Document : api.vmcloud.com/docs
â”œâ”€â”€ Statut : âœ… Ã€ jour (auto-generated)
â”œâ”€â”€ Format : OpenAPI / Swagger
â””â”€â”€ Coverage : 100% endpoints

SECURITY
â”œâ”€â”€ Document : SECURITY.md
â”œâ”€â”€ Statut : ðŸ”„ En cours
â”œâ”€â”€ Contenu : Policies, procedures
â””â”€â”€ Localisation : GitHub /docs (private)

DISASTER RECOVERY
â”œâ”€â”€ Document : DR-PLAN.md
â”œâ”€â”€ Statut : ðŸ”„ Ã€ complÃ©ter
â”œâ”€â”€ Contenu : Scenarios, procedures
â””â”€â”€ Localisation : GitHub /docs

ONBOARDING (New ops team member)
â”œâ”€â”€ Document : ONBOARDING.md
â”œâ”€â”€ Statut : âœ… Ã€ jour
â”œâ”€â”€ Contenu : AccÃ¨s, tools, training
â””â”€â”€ DurÃ©e : 2 semaines
```

---

## 9. Vendor Management

### 9.1 Fournisseurs critiques

```
FOURNISSEURS OPÃ‰RATIONNELS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

INFRASTRUCTURE
â”œâ”€â”€ OVHcloud
â”‚   â”œâ”€â”€ Service : Bare metal, Network
â”‚   â”œâ”€â”€ CriticitÃ© : ðŸ”´ Critique
â”‚   â”œâ”€â”€ SLA : 99.9%
â”‚   â”œâ”€â”€ Contact : Account manager + Support
â”‚   â””â”€â”€ Contrat : Startup Program (2027)

MONITORING / ALERTING
â”œâ”€â”€ PagerDuty
â”‚   â”œâ”€â”€ Service : Incident management
â”‚   â”œâ”€â”€ CriticitÃ© : ðŸŸ¡ Haute
â”‚   â”œâ”€â”€ Alternative : Opsgenie
â”‚   â””â”€â”€ CoÃ»t : ~$30/user/mois

â”œâ”€â”€ Grafana Cloud (optionnel)
â”‚   â”œâ”€â”€ Service : Metrics, logs (backup)
â”‚   â”œâ”€â”€ CriticitÃ© : ðŸŸ¢ Moyenne
â”‚   â””â”€â”€ CoÃ»t : Free tier

SECURITY
â”œâ”€â”€ Cloudflare
â”‚   â”œâ”€â”€ Service : DNS, CDN (optionnel)
â”‚   â”œâ”€â”€ CriticitÃ© : ðŸŸ¢ Moyenne
â”‚   â””â”€â”€ CoÃ»t : Free - $200/mois

â”œâ”€â”€ Let's Encrypt
â”‚   â”œâ”€â”€ Service : SSL certificates
â”‚   â”œâ”€â”€ CriticitÃ© : ðŸŸ¢ Moyenne
â”‚   â”œâ”€â”€ Alternative : ZeroSSL
â”‚   â””â”€â”€ CoÃ»t : Gratuit

CDN
â”œâ”€â”€ BunnyCDN
â”‚   â”œâ”€â”€ Service : Content delivery
â”‚   â”œâ”€â”€ CriticitÃ© : ðŸŸ¢ Moyenne
â”‚   â””â”€â”€ CoÃ»t : Usage-based (~$50/mois)
```

### 9.2 Risques fournisseurs

```
MATRICE DE RISQUE FOURNISSEURS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                    Impact
                    Low      Med      High
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
ProbabilitÃ©   â”‚Cloudflareâ”‚         â”‚         â”‚
High          â”‚Let'sEncrâ”‚         â”‚         â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Medium        â”‚ BunnyCDNâ”‚PagerDutyâ”‚  OVH    â”‚
              â”‚         â”‚         â”‚ (2027)  â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Low           â”‚  Other  â”‚         â”‚ NVIDIA  â”‚
              â”‚         â”‚         â”‚ shortageâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MITIGATION OVH (CRITIQUE)
â”œâ”€â”€ Timeline : 2027 (fin programme)
â”œâ”€â”€ Actions :
â”‚   â”œâ”€â”€ 2025 : Documenter infra portable
â”‚   â”œâ”€â”€ 2026 : POC alternatives
â”‚   â”œâ”€â”€ 2026-Q2 : NÃ©gociation OVH
â”‚   â””â”€â”€ 2027 : ExÃ©cution plan choisi
â””â”€â”€ Budget migration : 50-100Kâ‚¬ reserve
```

---

## 10. Roadmap OpÃ©rations

### 10.1 Court terme (Q1-Q2 2025)

```
OBJECTIFS Q1-Q2 2025
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MONITORING
â”œâ”€â”€ [ ] Client alerting (notifications custom)
â”œâ”€â”€ [ ] Dashboard client amÃ©liorÃ©
â”œâ”€â”€ [ ] Metrics retention 1 an
â””â”€â”€ Budget : ~200â‚¬/mois

AUTOMATION
â”œâ”€â”€ [ ] Auto-scaling containers
â”œâ”€â”€ [ ] Automated certificate management
â”œâ”€â”€ [ ] Self-service backup restore
â””â”€â”€ Budget : Dev time

PROCESS
â”œâ”€â”€ [ ] Runbooks review & update
â”œâ”€â”€ [ ] DR test (annual)
â”œâ”€â”€ [ ] Security audit
â””â”€â”€ Budget : 5Kâ‚¬ (external audit)

Ã‰QUIPE
â”œâ”€â”€ [ ] SRE contractor : Maintain
â”œâ”€â”€ [ ] CRE : Maintain
â””â”€â”€ Trigger hire : MRR > 30Kâ‚¬
```

### 10.2 Moyen terme (Q3-Q4 2025)

```
OBJECTIFS Q3-Q4 2025
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCALE
â”œâ”€â”€ [ ] Hire SRE #2 (si MRR > 50Kâ‚¬)
â”œâ”€â”€ [ ] Implement on-call rotation
â”œâ”€â”€ [ ] 24/7 support coverage
â””â”€â”€ Budget : ~60Kâ‚¬/an

FEATURES
â”œâ”€â”€ [ ] VM auto-scaling
â”œâ”€â”€ [ ] Multi-DC failover
â”œâ”€â”€ [ ] Managed databases
â””â”€â”€ Budget : Dev time

COMPLIANCE
â”œâ”€â”€ [ ] ISO 27001 preparation
â”œâ”€â”€ [ ] SOC 2 preparation
â”œâ”€â”€ [ ] Security program formalisÃ©
â””â”€â”€ Budget : 20-50Kâ‚¬
```

### 10.3 Long terme (2026+)

```
VISION OPERATIONS 2026+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ã‰QUIPE
â”œâ”€â”€ SRE Lead + 1-2 SRE
â”œâ”€â”€ Support team (2-3)
â”œâ”€â”€ DevOps / Platform engineer
â””â”€â”€ Security specialist

CAPABILITIES
â”œâ”€â”€ Multi-DC active-active
â”œâ”€â”€ Zero-downtime everything
â”œâ”€â”€ Automated DR
â”œâ”€â”€ AI-assisted ops
â””â”€â”€ NoOps pour clients (fully managed)

MÃ‰TRIQUES CIBLES
â”œâ”€â”€ Uptime : 99.9%
â”œâ”€â”€ MTTR : < 15 min
â”œâ”€â”€ Client/Ops ratio : 200:1
â”œâ”€â”€ Automation : 95%
â””â”€â”€ Zero P0 incidents
```

---

*Document maintenu par l'Ã©quipe Operations VMCloud*
*DerniÃ¨re mise Ã  jour : DÃ©cembre 2024*
*Prochaine rÃ©vision : Mars 2025*
